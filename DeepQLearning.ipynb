{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#auto reload modules \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "import pygame\n",
    "import torch \n",
    "config = yaml.load(open('SnakeDeepQ.yaml', 'r'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snake_env import SnakeEnv\n",
    "from deepQ import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "snakie = SnakeEnv({\"render_mode\":\"human\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(snakie.observation_space, snakie.action_space, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = snakie.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8304, 0.1291, 0.3625, 0.3002])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.compute_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward :  -13\n",
      "epsilon :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\SnakeDeepQ\\deepQ.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward :  -11\n",
      "epsilon :  0.99\n",
      "total reward :  -9\n",
      "epsilon :  0.9801\n",
      "total reward :  -8\n",
      "epsilon :  0.9702989999999999\n",
      "total reward :  -7\n",
      "epsilon :  0.96059601\n",
      "total reward :  -10\n",
      "epsilon :  0.9509900498999999\n",
      "total reward :  -9\n",
      "epsilon :  0.9414801494009999\n",
      "total reward :  -8\n",
      "epsilon :  0.9320653479069899\n",
      "total reward :  -7\n",
      "epsilon :  0.92274469442792\n",
      "total reward :  -7\n",
      "epsilon :  0.9135172474836407\n",
      "total reward :  -9\n",
      "epsilon :  0.9043820750088043\n",
      "total reward :  -9\n",
      "epsilon :  0.8953382542587163\n",
      "total reward :  -8\n",
      "epsilon :  0.8863848717161291\n",
      "total reward :  -12\n",
      "epsilon :  0.8775210229989678\n",
      "total reward :  -9\n",
      "epsilon :  0.8687458127689781\n",
      "total reward :  -13\n",
      "epsilon :  0.8600583546412883\n",
      "total reward :  -10\n",
      "epsilon :  0.8514577710948754\n",
      "total reward :  -11\n",
      "epsilon :  0.8429431933839266\n",
      "total reward :  -9\n",
      "epsilon :  0.8345137614500874\n",
      "total reward :  -12\n",
      "epsilon :  0.8261686238355865\n",
      "total reward :  -13\n",
      "epsilon :  0.8179069375972307\n",
      "total reward :  -9\n",
      "epsilon :  0.8097278682212583\n",
      "total reward :  -12\n",
      "epsilon :  0.8016305895390458\n",
      "total reward :  -9\n",
      "epsilon :  0.7936142836436553\n",
      "total reward :  -7\n",
      "epsilon :  0.7856781408072188\n",
      "total reward :  -16\n",
      "epsilon :  0.7778213593991465\n",
      "total reward :  -13\n",
      "epsilon :  0.7700431458051551\n",
      "total reward :  -13\n",
      "epsilon :  0.7623427143471035\n",
      "total reward :  -10\n",
      "epsilon :  0.7547192872036325\n",
      "total reward :  -10\n",
      "epsilon :  0.7471720943315961\n",
      "total reward :  -8\n",
      "epsilon :  0.7397003733882802\n",
      "total reward :  -6\n",
      "epsilon :  0.7323033696543974\n",
      "total reward :  -10\n",
      "epsilon :  0.7249803359578534\n",
      "total reward :  -13\n",
      "epsilon :  0.7177305325982748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m steps \u001b[39m>\u001b[39m max_steps:\n\u001b[0;32m     23\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     snakie\u001b[39m.\u001b[39;49mrender(\u001b[39m\"\u001b[39;49m\u001b[39mhuman\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m steps \u001b[39m>\u001b[39m max_steps:\n\u001b[0;32m     26\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\SnakeDeepQ\\snake_env.py:145\u001b[0m, in \u001b[0;36mSnakeEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    143\u001b[0m pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m    144\u001b[0m \u001b[39m# Wait 100 milliseconds\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m pygame\u001b[39m.\u001b[39mtime\u001b[39m.\u001b[39mdelay(\u001b[39m100\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "snakie = SnakeEnv({\"render_mode\": \"human\"})\n",
    "pygame.time.wait(1000)\n",
    "while True:\n",
    "    #collect experience : \n",
    "    max_steps = 200\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    while True: \n",
    "        state = snakie.reset()[0]\n",
    "        done = False \n",
    "\n",
    "        while not done :\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "            action = agent.compute_action(state)\n",
    "            next_state, reward, done, _ = snakie.step(action)\n",
    "            agent.add_experience(state, torch.argmax(action), reward, next_state, done)\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            total_reward += reward\n",
    "            if steps > max_steps:\n",
    "                break\n",
    "            snakie.render(\"human\")\n",
    "        if steps > max_steps:\n",
    "            break\n",
    "    print(\"total reward : \", total_reward)\n",
    "    print(\"epsilon : \", agent.epsilon)\n",
    "    # train the agent\n",
    "    agent.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
